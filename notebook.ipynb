{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display_figures = True\n",
    "\n",
    "def display_correlation_matrix(X,y):\n",
    "    if not display_figures:\n",
    "        return\n",
    "\n",
    "    Xy = pd.concat([X, y], axis=1)\n",
    "    corr = Xy.corr()\n",
    "    f = plt.figure(figsize=(20, 20))\n",
    "    plt.matshow(corr, fignum=f.number)\n",
    "    plt.xticks(range(Xy.shape[1]), Xy.columns, fontsize=14, rotation=90)\n",
    "    plt.yticks(range(Xy.shape[1]), Xy.columns, fontsize=14)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title('Correlation Matrix', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data analysis and manipulation tool\n",
    "import numpy as np # Numerical computing tools\n",
    "import matplotlib.pyplot as plt # another visualization library\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skrebate import ReliefF\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = 'virus_hw2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(labels=['Address', 'Job', 'PatientID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Split to train, validate and test sets\n",
    "\n",
    "The ratio is 70% for training, 15% for validating and 15% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(labels=['TestResultsCode'], axis=1)\n",
    "y = df[['TestResultsCode']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.176, random_state=1) # 0.176 x 0.85 = 0.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Fix the data types\n",
    "\n",
    "Fixing CurrentLocation lat long type - separate into 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = [\n",
    "    'not_detected_Spreader_NotatRisk',\n",
    "    'not_detected_NotSpreader_atRisk',\n",
    "    'not_detected_NotSpreader_NotatRisk',\n",
    "    'not_detected_Spreader_atRisk',\n",
    "    'cold_NotSpreader_NotatRisk',\n",
    "    'cold_Spreader_NotatRisk',\n",
    "    'cold_Spreader_atRisk',\n",
    "    'cold_NotSpreader_atRisk',\n",
    "    'flue_NotSpreader_NotatRisk',\n",
    "    'flue_NotSpreader_atRisk',\n",
    "    'flue_Spreader_NotatRisk',\n",
    "    'covid_NotSpreader_atRisk',\n",
    "    'covid_Spreader_NotatRisk',\n",
    "    'flue_Spreader_atRisk',\n",
    "    'covid_NotSpreader_NotatRisk',\n",
    "    'covid_Spreader_atRisk',\n",
    "    'cmv_NotSpreader_NotatRisk',\n",
    "    'cmv_Spreader_atRisk',\n",
    "    'cmv_NotSpreader_atRisk',\n",
    "    'cmv_Spreader_NotatRisk',\n",
    "    'measles_Spreader_NotatRisk',\n",
    "    'measles_NotSpreader_NotatRisk',\n",
    "    'measles_NotSpreader_atRisk',\n",
    "    'measles_Spreader_atRisk',\n",
    "]\n",
    "\n",
    "convert_features_dict = {\n",
    "    'AgeGroup':  pd.CategoricalDtype(categories=range(0,9)),\n",
    "    'BloodType': pd.CategoricalDtype(categories=['AB-', 'A+', 'AB+', 'A-', 'B-', 'O-', 'B+', 'O+']),\n",
    "    'Sex':  pd.CategoricalDtype(categories=['M', 'F']),\n",
    "    'SyndromeClass': pd.CategoricalDtype(categories=range(1,5))\n",
    "}\n",
    "\n",
    "convert_label_dict = {\n",
    "    'TestResultsCode': pd.CategoricalDtype(categories=label_categories)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fix_data_types(X):\n",
    "    return X.astype(convert_features_dict)\n",
    "\n",
    "data_types_transofrmer = FunctionTransformer(fix_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fix_label_type(y):\n",
    "    y = y.astype(convert_label_dict)\n",
    "#     y.update(y[['TestResultsCode']].apply(lambda x: x.cat.codes))\n",
    "#     y = y.astype({'TestResultsCode': int})\n",
    "    return y\n",
    "\n",
    "label_transformer = FunctionTransformer(fix_label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotCategorical():\n",
    "    def __init__(self):\n",
    "        self.onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.categorical_features = ['AgeGroup', 'Sex', 'BloodType', 'SyndromeClass']\n",
    "\n",
    "    def fit(self, X, y, **kargs):\n",
    "        self.onehot_encoder.fit(X[self.categorical_features])\n",
    "        print(self.onehot_encoder.get_feature_names())\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[self.onehot_encoder.get_feature_names()] = self.onehot_encoder.transform(X[self.categorical_features])\n",
    "        X = X.drop(labels=self.categorical_features, axis=1)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y, **kwargs):\n",
    "        self.fit(X,y, **kwargs)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle AgeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_age_group(X):\n",
    "    return pd.get_dummies(X, columns=[\"AgeGroup\"], prefix=[\"AgeGroup\"])\n",
    "\n",
    "age_group_transformer = FunctionTransformer(handle_age_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_sex_type(X):\n",
    "    return pd.get_dummies(X, columns=[\"Sex\"], prefix=[\"Sex\"])\n",
    "\n",
    "sex_type_transformer = FunctionTransformer(handle_sex_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle BloodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blood_type(X):\n",
    "    return pd.get_dummies(X, columns=[\"BloodType\"], prefix=[\"BloodType\"])\n",
    "\n",
    "blood_type_transformer = FunctionTransformer(handle_blood_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle DateOfPCRTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_date_of_pcr_test(X):\n",
    "    X['DateOfPCRTest'] = pd.to_datetime(X['DateOfPCRTest'], infer_datetime_format=True)\n",
    "    X['DateOfPCRTest'] = X['DateOfPCRTest'].values.astype(float)\n",
    "    X['DateOfPCRTest'].values[X['DateOfPCRTest'].values < 0] = np.nan\n",
    "    return X\n",
    "\n",
    "date_of_pcr_test_type_transformer = FunctionTransformer(handle_date_of_pcr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle SyndromeClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_syndrome_class(X):\n",
    "    return pd.get_dummies(X, columns=[\"SyndromeClass\"], prefix=[\"SyndromeClass\"])\n",
    "\n",
    "syndrome_class_transformer = FunctionTransformer(handle_syndrome_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle location\n",
    "\n",
    "we separate the location into 2 features for longitude and latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_location(X):\n",
    "    long_lat_df = X['CurrentLocation'].str.strip('(Decimal').str.split(', ', expand=True).rename(columns={0:'Lat', 1:'Long'})\n",
    "    X['CurrentLocation_Lat'] = long_lat_df['Lat'].str.strip(\"')\")\n",
    "    X['CurrentLocation_Long'] = long_lat_df['Long'].str.strip(\"Decimal('\").str.rstrip(\"'))\")\n",
    "\n",
    "    convert_dict = {\n",
    "        'CurrentLocation_Lat': float,\n",
    "        'CurrentLocation_Long': float,\n",
    "    }\n",
    "\n",
    "    X = X.astype(convert_dict)\n",
    "    return X.drop(labels=['CurrentLocation'], axis=1)\n",
    "\n",
    "location_transformer = FunctionTransformer(handle_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle symptoms\n",
    "\n",
    "We create a one-hot vector of all symptoms and remove the old mixed feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_symptoms(X):\n",
    "    splitted_df = X['SelfDeclarationOfIllnessForm'].str.split(';', expand=True)\n",
    "    values = splitted_df.values.flatten()\n",
    "    unique_values = pd.unique(values).tolist()\n",
    "    stripped_unique_values = [str(val).strip(' ') for val in unique_values]\n",
    "\n",
    "    # Split by ; to create a list for each row\n",
    "    X['SelfDeclarationOfIllnessForm_list'] = X['SelfDeclarationOfIllnessForm'].str.split(';')\n",
    "\n",
    "    # Replace NAN values with empty list\n",
    "    isna = X['SelfDeclarationOfIllnessForm_list'].isna()\n",
    "    X.loc[isna, 'SelfDeclarationOfIllnessForm_list'] = pd.Series([['nan']] * isna.sum()).values\n",
    "\n",
    "    # strip whitespaces\n",
    "    X['SelfDeclarationOfIllnessForm_list'] = [[str(val).strip() for val in list(symptom_list)]\n",
    "                                              for symptom_list in X['SelfDeclarationOfIllnessForm_list'].values]\n",
    "\n",
    "    # Create columns\n",
    "    for column_name in stripped_unique_values:\n",
    "        X[column_name] = X['SelfDeclarationOfIllnessForm_list'].map(lambda l: 1 if column_name in l else 0)\n",
    "\n",
    "    # Rename no symptoms column\n",
    "    # Drop irrelevant features\n",
    "    X = X.rename(columns={'nan': 'No_Symptoms'})\\\n",
    "        .drop(labels=['SelfDeclarationOfIllnessForm','SelfDeclarationOfIllnessForm_list'], axis=1)\n",
    "    return X\n",
    "\n",
    "symptoms_transformer = FunctionTransformer(handle_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_data_types_pipeline = Pipeline([\n",
    "    ('handle_types', data_types_transofrmer),\n",
    "    ('handle_categorical', OneHotCategorical()),\n",
    "    ('handle_date_of_pcr_test', date_of_pcr_test_type_transformer),\n",
    "    ('handle_location', location_transformer),\n",
    "    ('handle_symptoms', symptoms_transformer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'AvgHouseholdExpenseOnPresents', \n",
    "    'AvgHouseholdExpenseOnSocialGames',\n",
    "    'AvgHouseholdExpenseParkingTicketsPerYear',\n",
    "    'AvgMinSportsPerDay',\n",
    "    'AvgTimeOnSocialMedia',\n",
    "    'AvgTimeOnStuding',\n",
    "    'BMI',\n",
    "    'DateOfPCRTest',\n",
    "    'NrCousins',\n",
    "    'StepsPerYear',\n",
    "    'TimeOnSocialActivities',\n",
    "    'pcrResult1',\n",
    "    'pcrResult2',\n",
    "    'pcrResult3',\n",
    "    'pcrResult4',\n",
    "    'pcrResult5',\n",
    "    'pcrResult6',\n",
    "    'pcrResult7',\n",
    "    'pcrResult8',\n",
    "    'pcrResult9',\n",
    "    'pcrResult10',\n",
    "    'pcrResult11',\n",
    "    'pcrResult12',\n",
    "    'pcrResult13',\n",
    "    'pcrResult14',\n",
    "    'pcrResult15',\n",
    "    'pcrResult16',\n",
    "    'CurrentLocation_Lat',\n",
    "    'CurrentLocation_Long']\n",
    "\n",
    "\n",
    "categorical_features = [\n",
    "    'AgeGroup_1',\n",
    "       'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6',\n",
    "       'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1',\n",
    "       'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3',\n",
    "       'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7',\n",
    "       'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2',\n",
    "       'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5'\n",
    "]\n",
    "\n",
    "\n",
    "class Imputer:\n",
    "    def __init__(self):\n",
    "        self.iterative_imputer = IterativeImputer(initial_strategy='median')\n",
    "        self.knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    def fit(self, X, y, **kargs):\n",
    "        self.iterative_imputer.fit(X[numeric_features])\n",
    "        self.knn_imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[numeric_features] = self.iterative_imputer.transform(X[numeric_features])\n",
    "        print(X.columns)\n",
    "        res = self.knn_imputer.transform(X)\n",
    "        X = pd.DataFrame(res, columns=X.columns)\n",
    "        X[categorical_features] = X[categorical_features].round().astype(int)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y, **kwargs):\n",
    "        self.fit(X,y, **kwargs)\n",
    "        return self.transform(X)\n",
    "\n",
    "imputation_transformer = Imputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OutlierClipper transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierClipper:\n",
    "    def __init__(self, features):\n",
    "        self._features = features\n",
    "        self._feature_map = {}\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        df = X[self._features]\n",
    "        features = list(df.columns)\n",
    "        for feature in features:\n",
    "            f_q1 = df[feature].quantile(0.25)\n",
    "            f_q3 = df[feature].quantile(0.75)\n",
    "            f_iqr = f_q3 - f_q1\n",
    "            self._feature_map[feature] = (f_q1 - (1.5 * f_iqr), f_q3 + (1.5 * f_iqr))\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        data_copy = data.copy()\n",
    "        for feature in self._feature_map.keys():\n",
    "            data_copy[feature] = data_copy[feature].clip(lower=self._feature_map[feature][0],\n",
    "                                                         upper=self._feature_map[feature][1])\n",
    "        return data_copy\n",
    "\n",
    "    def fit_transform(self, X, y, **kwargs):\n",
    "        self.fit(X, y, **kwargs)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_features = ['StepsPerYear',\n",
    "                    'TimeOnSocialActivities',\n",
    "                    'AvgHouseholdExpenseOnPresents',\n",
    "                    'AvgHouseholdExpenseOnSocialGames',\n",
    "                    'AvgHouseholdExpenseParkingTicketsPerYear',\n",
    "                    'AvgMinSportsPerDay',\n",
    "                    'AvgTimeOnSocialMedia',\n",
    "                    'AvgTimeOnStuding',\n",
    "                    'BMI',\n",
    "                    'pcrResult1',\n",
    "                    'pcrResult10',\n",
    "                    'pcrResult11',\n",
    "                    'pcrResult12',\n",
    "                    'pcrResult13',\n",
    "                    'pcrResult14',\n",
    "                    'pcrResult15',\n",
    "                    'pcrResult16',\n",
    "                    'pcrResult2',\n",
    "                    'pcrResult3',\n",
    "                    'pcrResult4',\n",
    "                    'pcrResult5',\n",
    "                    'pcrResult6',\n",
    "                    'pcrResult7',\n",
    "                    'pcrResult8',\n",
    "                    'pcrResult9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_transformer = OutlierClipper(features=continous_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scaled_features = ['AvgHouseholdExpenseOnPresents',\n",
    "    'AvgHouseholdExpenseOnSocialGames',\n",
    "    'AvgHouseholdExpenseParkingTicketsPerYear',\n",
    "    'AvgMinSportsPerDay',\n",
    "    'AvgTimeOnSocialMedia',\n",
    "    'AvgTimeOnStuding',\n",
    "    'BMI',\n",
    "    'DateOfPCRTest',\n",
    "    'DisciplineScore',\n",
    "    'HappinessScore',\n",
    "    'NrCousins',\n",
    "    'StepsPerYear',\n",
    "    'TimeOnSocialActivities',\n",
    "    'pcrResult14',\n",
    "    'pcrResult16']\n",
    "\n",
    "negative_scaled_features = [\n",
    "    'pcrResult1',\n",
    "    'pcrResult10',\n",
    "    'pcrResult11',\n",
    "    'pcrResult12',\n",
    "    'pcrResult13',\n",
    "    'pcrResult15',\n",
    "    'pcrResult2',\n",
    "    'pcrResult3',\n",
    "    'pcrResult4',\n",
    "    'pcrResult5',\n",
    "    'pcrResult6',\n",
    "    'pcrResult7',\n",
    "    'pcrResult8',\n",
    "    'pcrResult9',\n",
    "]\n",
    "\n",
    "class Normalizer:\n",
    "    def __init__(self):\n",
    "        self.min_max_scaler = MinMaxScaler()\n",
    "        self.max_abs_scaler = MaxAbsScaler()\n",
    "\n",
    "    def fit(self, X, y, **kargs):\n",
    "        self.min_max_scaler.fit(X[positive_scaled_features])\n",
    "        self.max_abs_scaler.fit(X[negative_scaled_features])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kargs):\n",
    "        X[positive_scaled_features] = self.min_max_scaler.transform(X[positive_scaled_features])\n",
    "        X[negative_scaled_features] = self.max_abs_scaler.transform(X[negative_scaled_features])\n",
    "        \n",
    "        X['CurrentLocation_Lat'] /= 180\n",
    "        X['CurrentLocation_Long'] /= 180\n",
    "        \n",
    "        return X\n",
    "    \n",
    "normalize_transformer = Normalizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['cmv', 'cold', 'covid', 'flue', 'measles', 'not_detected']\n",
    "labels = pd.DataFrame()\n",
    "labels['is_spreader'] = pd.Series([0 if 'NotSpreader' in row else 1 for row in df['TestResultsCode']])\n",
    "labels['is_at_risk'] = pd.Series([0 if 'NotatRisk' in row else 1 for row in df['TestResultsCode']])\n",
    "for d in diseases:\n",
    "    labels[d] = pd.Series([1 if d in row else 0 for row in df['TestResultsCode']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection with Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_filter(X, y):\n",
    "    relief = RFE(ReliefF(), n_features_to_select=20, step = 0.5, verbose=True)\n",
    "    feature_selector = relief.fit(X, y['TestResultsCode'].values.codes)\n",
    "    print('Selected Features:', X.columns[feature_selector.support_])\n",
    "    return feature_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import LinearSVC## Feature selection with Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_wrapper(X,y):\n",
    "#     svc = SVC(gamma='auto')\n",
    "    linearSVC = LinearSVC(random_state=0, tol=1e-5, class_weight='balanced')\n",
    "    random_forest_clssifier = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "    # knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    sfs = SequentialFeatureSelector(linearSVC, k_features=25, forward=False, floating=False, verbose=5, cv=0, n_jobs=-1)\n",
    "    sfs.fit(X, y)\n",
    "\n",
    "    print(sfs.k_feature_names_)\n",
    "\n",
    "    return sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_preperation_pipelines = Pipeline([\n",
    "    ('feature_types', features_data_types_pipeline),\n",
    "    ('feature_imputation', imputation_transformer),\n",
    "    ('outlier_clipping', outlier_transformer),\n",
    "    ('normalization', normalize_transformer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgeGroup_1', 'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6', 'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1', 'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3', 'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7', 'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2', 'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5']\n",
      "Index(['AvgHouseholdExpenseOnPresents', 'AvgHouseholdExpenseOnSocialGames',\n",
      "       'AvgHouseholdExpenseParkingTicketsPerYear', 'AvgMinSportsPerDay',\n",
      "       'AvgTimeOnSocialMedia', 'AvgTimeOnStuding', 'BMI', 'DateOfPCRTest',\n",
      "       'DisciplineScore', 'HappinessScore', 'NrCousins', 'StepsPerYear',\n",
      "       'TimeOnSocialActivities', 'pcrResult1', 'pcrResult10', 'pcrResult11',\n",
      "       'pcrResult12', 'pcrResult13', 'pcrResult14', 'pcrResult15',\n",
      "       'pcrResult16', 'pcrResult2', 'pcrResult3', 'pcrResult4', 'pcrResult5',\n",
      "       'pcrResult6', 'pcrResult7', 'pcrResult8', 'pcrResult9', 'AgeGroup_1',\n",
      "       'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6',\n",
      "       'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1',\n",
      "       'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3',\n",
      "       'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7',\n",
      "       'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2',\n",
      "       'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5',\n",
      "       'CurrentLocation_Lat', 'CurrentLocation_Long',\n",
      "       'Congestion_or_runny nose', 'Sore_throat', 'Muscle_or_body_aches',\n",
      "       'Shortness_of_breath', 'Headache', 'No_Symptoms', 'Chills', 'Diarrhea',\n",
      "       'Fatigue', 'New_loss_of_taste_or_smell', 'Nausea_or_vomiting',\n",
      "       'Skin_redness'],\n",
      "      dtype='object')\n",
      "Index(['AvgHouseholdExpenseOnPresents', 'AvgHouseholdExpenseOnSocialGames',\n",
      "       'AvgHouseholdExpenseParkingTicketsPerYear', 'AvgMinSportsPerDay',\n",
      "       'AvgTimeOnSocialMedia', 'AvgTimeOnStuding', 'BMI', 'DateOfPCRTest',\n",
      "       'DisciplineScore', 'HappinessScore', 'NrCousins', 'StepsPerYear',\n",
      "       'TimeOnSocialActivities', 'pcrResult1', 'pcrResult10', 'pcrResult11',\n",
      "       'pcrResult12', 'pcrResult13', 'pcrResult14', 'pcrResult15',\n",
      "       'pcrResult16', 'pcrResult2', 'pcrResult3', 'pcrResult4', 'pcrResult5',\n",
      "       'pcrResult6', 'pcrResult7', 'pcrResult8', 'pcrResult9', 'AgeGroup_1',\n",
      "       'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6',\n",
      "       'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1',\n",
      "       'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3',\n",
      "       'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7',\n",
      "       'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2',\n",
      "       'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5',\n",
      "       'CurrentLocation_Lat', 'CurrentLocation_Long',\n",
      "       'Congestion_or_runny nose', 'Sore_throat', 'Muscle_or_body_aches',\n",
      "       'Shortness_of_breath', 'Headache', 'No_Symptoms', 'Chills', 'Diarrhea',\n",
      "       'Fatigue', 'New_loss_of_taste_or_smell', 'Nausea_or_vomiting',\n",
      "       'Skin_redness'],\n",
      "      dtype='object')\n",
      "Index(['AvgHouseholdExpenseOnPresents', 'AvgHouseholdExpenseOnSocialGames',\n",
      "       'AvgHouseholdExpenseParkingTicketsPerYear', 'AvgMinSportsPerDay',\n",
      "       'AvgTimeOnSocialMedia', 'AvgTimeOnStuding', 'BMI', 'DateOfPCRTest',\n",
      "       'DisciplineScore', 'HappinessScore', 'NrCousins', 'StepsPerYear',\n",
      "       'TimeOnSocialActivities', 'pcrResult1', 'pcrResult10', 'pcrResult11',\n",
      "       'pcrResult12', 'pcrResult13', 'pcrResult14', 'pcrResult15',\n",
      "       'pcrResult16', 'pcrResult2', 'pcrResult3', 'pcrResult4', 'pcrResult5',\n",
      "       'pcrResult6', 'pcrResult7', 'pcrResult8', 'pcrResult9', 'AgeGroup_1',\n",
      "       'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6',\n",
      "       'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1',\n",
      "       'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3',\n",
      "       'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7',\n",
      "       'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2',\n",
      "       'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5',\n",
      "       'CurrentLocation_Lat', 'CurrentLocation_Long', 'Fatigue',\n",
      "       'Congestion_or_runny nose', 'Muscle_or_body_aches', 'Headache',\n",
      "       'Shortness_of_breath', 'No_Symptoms', 'Nausea_or_vomiting',\n",
      "       'Sore_throat', 'Skin_redness', 'Chills', 'Diarrhea',\n",
      "       'New_loss_of_taste_or_smell'],\n",
      "      dtype='object')\n",
      "Index(['AvgHouseholdExpenseOnPresents', 'AvgHouseholdExpenseOnSocialGames',\n",
      "       'AvgHouseholdExpenseParkingTicketsPerYear', 'AvgMinSportsPerDay',\n",
      "       'AvgTimeOnSocialMedia', 'AvgTimeOnStuding', 'BMI', 'DateOfPCRTest',\n",
      "       'DisciplineScore', 'HappinessScore', 'NrCousins', 'StepsPerYear',\n",
      "       'TimeOnSocialActivities', 'pcrResult1', 'pcrResult10', 'pcrResult11',\n",
      "       'pcrResult12', 'pcrResult13', 'pcrResult14', 'pcrResult15',\n",
      "       'pcrResult16', 'pcrResult2', 'pcrResult3', 'pcrResult4', 'pcrResult5',\n",
      "       'pcrResult6', 'pcrResult7', 'pcrResult8', 'pcrResult9', 'AgeGroup_1',\n",
      "       'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6',\n",
      "       'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1',\n",
      "       'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3',\n",
      "       'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7',\n",
      "       'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2',\n",
      "       'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5',\n",
      "       'CurrentLocation_Lat', 'CurrentLocation_Long', 'No_Symptoms',\n",
      "       'Shortness_of_breath', 'Diarrhea', 'New_loss_of_taste_or_smell',\n",
      "       'Headache', 'Sore_throat', 'Muscle_or_body_aches', 'Skin_redness',\n",
      "       'Congestion_or_runny nose', 'Fatigue', 'Nausea_or_vomiting', 'Chills'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_preperation_pipelines.fit(X_train, y_train)\n",
    "label_transformer.fit(y_train)\n",
    "\n",
    "X_train_prepared, y_train_prepared = data_preperation_pipelines.transform(X_train), label_transformer.transform(y_train)\n",
    "X_validation_prepared, y_validation_prepared = data_preperation_pipelines.transform(X_val), label_transformer.transform(y_val)\n",
    "X_test_prepared, y_test_prepared = data_preperation_pipelines.transform(X_test), label_transformer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AvgHouseholdExpenseOnPresents', 'AvgHouseholdExpenseOnSocialGames',\n",
       "       'AvgHouseholdExpenseParkingTicketsPerYear', 'AvgMinSportsPerDay',\n",
       "       'AvgTimeOnSocialMedia', 'AvgTimeOnStuding', 'BMI', 'DateOfPCRTest',\n",
       "       'DisciplineScore', 'HappinessScore', 'NrCousins', 'StepsPerYear',\n",
       "       'TimeOnSocialActivities', 'pcrResult1', 'pcrResult10', 'pcrResult11',\n",
       "       'pcrResult12', 'pcrResult13', 'pcrResult14', 'pcrResult15',\n",
       "       'pcrResult16', 'pcrResult2', 'pcrResult3', 'pcrResult4', 'pcrResult5',\n",
       "       'pcrResult6', 'pcrResult7', 'pcrResult8', 'pcrResult9', 'AgeGroup_1',\n",
       "       'AgeGroup_2', 'AgeGroup_3', 'AgeGroup_4', 'AgeGroup_5', 'AgeGroup_6',\n",
       "       'AgeGroup_7', 'AgeGroup_8', 'AgeGroup_9', 'AgeGroup_10', 'Sex_1',\n",
       "       'Sex_2', 'Sex_3', 'BloodType_1', 'BloodType_2', 'BloodType_3',\n",
       "       'BloodType_4', 'BloodType_5', 'BloodType_6', 'BloodType_7',\n",
       "       'BloodType_8', 'BloodType_9', 'SyndromeClass_1', 'SyndromeClass_2',\n",
       "       'SyndromeClass_3', 'SyndromeClass_4', 'SyndromeClass_5',\n",
       "       'CurrentLocation_Lat', 'CurrentLocation_Long',\n",
       "       'Congestion_or_runny nose', 'Sore_throat', 'Muscle_or_body_aches',\n",
       "       'Shortness_of_breath', 'Headache', 'No_Symptoms', 'Chills', 'Diarrhea',\n",
       "       'Fatigue', 'New_loss_of_taste_or_smell', 'Nausea_or_vomiting',\n",
       "       'Skin_redness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  1.1min finished\n",
      "\n",
      "[2020-12-06 13:15:45] Features: 69/25 -- score: 0.49114791547687037[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  69 | elapsed:   45.3s finished\n",
      "\n",
      "[2020-12-06 13:16:30] Features: 68/25 -- score: 0.4945745288406625[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  68 | elapsed:   39.8s finished\n",
      "\n",
      "[2020-12-06 13:17:11] Features: 67/25 -- score: 0.49571673329525984[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of  67 | elapsed:   52.1s finished\n",
      "\n",
      "[2020-12-06 13:18:03] Features: 66/25 -- score: 0.4960022844089092[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:   38.3s finished\n",
      "\n",
      "[2020-12-06 13:18:41] Features: 65/25 -- score: 0.4971444888635066[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:   40.3s finished\n",
      "\n",
      "[2020-12-06 13:19:22] Features: 64/25 -- score: 0.49800114220445457[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   39.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   40.2s finished\n",
      "\n",
      "[2020-12-06 13:20:02] Features: 63/25 -- score: 0.4985722444317533[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  63 | elapsed:   42.1s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:   42.8s finished\n",
      "\n",
      "[2020-12-06 13:20:45] Features: 62/25 -- score: 0.4985722444317533[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  62 | elapsed: 11.2min remaining:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed: 11.2min finished\n",
      "\n",
      "[2020-12-06 13:31:56] Features: 61/25 -- score: 0.4985722444317533[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  61 | elapsed:   33.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:   33.5s finished\n",
      "\n",
      "[2020-12-06 13:32:29] Features: 60/25 -- score: 0.49771559109080526[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed:   24.8s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   24.8s finished\n",
      "\n",
      "[2020-12-06 13:32:54] Features: 59/25 -- score: 0.4971444888635066[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  59 | elapsed:   21.5s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:   22.6s finished\n",
      "\n",
      "[2020-12-06 13:33:17] Features: 58/25 -- score: 0.49800114220445457[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.7s\n"
     ]
    }
   ],
   "source": [
    "select_features_wrapper(X_train_prepared, y_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_filter(X_train_prepared, y_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_correlation_matrix(X_train_prepared, y_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(X_trainn_prepared, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prepared.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ml_hw2)",
   "language": "python",
   "name": "pycharm-64409fe0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
